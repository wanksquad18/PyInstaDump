name: Run Instagram Follower Scraper

# Triggers:
# - manual run via Actions UI
# - scheduled run daily at 02:00 UTC (change or remove as desired)
on:
  workflow_dispatch:
  schedule:
    - cron: '0 2 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 240

    env:
      # How many followers to collect (override by editing workflow or add env secret)
      FOLLOWERS_LIMIT: '1000'
      # Optional small delay between profile visits (seconds)
      PROFILE_DELAY: '0.8'
      # Optional scroll pause (seconds)
      SCROLL_PAUSE: '0.6'

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies (for Playwright / browsers)
        run: |
          sudo apt-get update -y
          sudo apt-get install -y --no-install-recommends \
            ca-certificates \
            libnss3 \
            libatk-bridge2.0-0 \
            libgtk-3-0 \
            libxss1 \
            libasound2t64 \
            libasound2-data \
            libgbm1 \
            libglib2.0-0 \
            libx11-6 \
            libxcomposite1 \
            libxcursor1 \
            libxdamage1 \
            libxrandr2 \
            libxinerama1 \
            libpangocairo-1.0-0 \
            libpango-1.0-0 \
            libatk1.0-0 \
            libcups2 \
            libnspr4 \
            libxext6 \
            libffi-dev \
            libx264-dev \
            ffmpeg \
            wget \
            unzip || true

      - name: Install Python packages and Playwright browsers
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; else pip install playwright aiohttp; fi
          # Install Playwright browsers (with system deps)
          python -m playwright install --with-deps

      - name: Show environment & files (debug)
        run: |
          echo "FOLLOWERS_LIMIT=$FOLLOWERS_LIMIT"
          echo "PROFILE_DELAY=$PROFILE_DELAY"
          echo "SCROLL_PAUSE=$SCROLL_PAUSE"
          ls -la
          echo "usernames.txt:"
          sed -n '1,20p' usernames.txt || true

      - name: Run follower scraper
        env:
          # Pass cookie secret into the script via env
          COOKIES: ${{ secrets.COOKIES }}
          # Optional override limit here (string)
          FOLLOWERS_LIMIT: ${{ env.FOLLOWERS_LIMIT }}
          PROFILE_DELAY: ${{ env.PROFILE_DELAY }}
          SCROLL_PAUSE: ${{ env.SCROLL_PAUSE }}
        run: |
          mkdir -p data
          # Run the follower scraper script (must exist at repo root)
          python scrape_followers.py
          # show first lines of output for logs
          echo "---- results.csv preview ----"
          head -n 20 data/results.csv || true

      - name: Upload results artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ig-profile-results
          path: data/results.csv
